# ğŸ” Log Analyzer â€“ Analyse intelligente des logs Apache avec Machine Learning

Ce projet analyse automatiquement les logs Apache afin de dÃ©tecter des comportements suspects, des erreurs et des anomalies grÃ¢ce Ã  des algorithmes de **Machine Learning non supervisÃ©** (KMeans + Isolation Forest).  
Il inclut un pipeline complet : collecte â†’ preprocessing â†’ analyse IA â†’ visualisation dans un tableau de bord.

---

## ğŸš€ FonctionnalitÃ©s

- ğŸ“¥ Collecte automatique des logs Apache (`access_log`)
- ğŸ—„ Stockage structurÃ© dans **MongoDB** (Docker)
- ğŸ§¹ PrÃ©processing et extraction de features
- ğŸ¤– DÃ©tection dâ€™anomalies (Isolation Forest)
- ğŸ” Clustering de comportements (KMeans)
- ğŸ“Š Dashboard interactif avec **Streamlit**
- âœ” Architecture claire, modulaire et extensible

---

## ğŸ§© Architecture du projet

log-analyzer/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ access.log # Logs Apache bruts
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ collector.py # Extraction & insertion dans MongoDB
â”‚ â”œâ”€â”€ preprocess.py # Mise en forme & ajout de features
â”‚ â”œâ”€â”€ analyzer.py # Analyse IA : clustering + anomalies
â”‚ â””â”€â”€ dashboard.py # Tableau de bord Streamlit
â”‚
â”œâ”€â”€ docker-compose.yml # Service MongoDB
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â””â”€â”€ README.md # Documentation


---

## ğŸ§  Pipeline dâ€™analyse (explication claire)

### 1ï¸âƒ£ **Collector â€“ extraction des logs**
`collector.py` lit le fichier systeme :

/var/log/apache2/access_log


Il parse chaque ligne (IP, timestamp, URL, code HTTP, taille) et lâ€™insÃ¨re dans MongoDB.

---

### 2ï¸âƒ£ **Preprocess â€“ transformation des donnÃ©es**
`preprocess.py` :

- convertit le timestamp en format datetime
- extrait lâ€™heure (`hour`)
- ajoute un flag erreur (`is_error = 1 si status >= 400`)
- renvoie un DataFrame propre pour le ML

---

### 3ï¸âƒ£ **Analyzer â€“ Machine Learning**
`analyzer.py` applique deux modÃ¨les non supervisÃ©s :

#### ğŸ”¹ **KMeans (clustering)**
â†’ regroupe les comportements similaires du serveur  
(ex : cluster de 200, cluster de 404, cluster de pages sensiblesâ€¦)

#### ğŸ”¹ **Isolation Forest (anomalies)**
â†’ dÃ©tecte les requÃªtes rares ou atypiques

RÃ©sultat ajoutÃ© pour chaque log :

- `cluster`
- `anomaly` (1 = normal, -1 = anomalie)
- `anomaly_score` (plus nÃ©gatif = plus suspect)

Les rÃ©sultats sont sauvegardÃ©s dans la collection :

logs_db.results


---

### 4ï¸âƒ£ **Dashboard â€“ visualisation**
`dashboard.py` affiche :

- nombre total de logs
- nombre dâ€™erreurs
- anomalies dÃ©tectÃ©es
- graphiques dâ€™activitÃ©
- table complÃ¨te filtrable

Accessible via :

ğŸ‘‰ http://localhost:8501

---

## ğŸ›  Installation

### 1. Cloner le projet

git clone https://github.com/<username>/log-analyzer.git
cd log-analyzer
2. Activer un environnement virtuel
bash
Copier le code
python3 -m venv .venv
source .venv/bin/activate
3. Installer les dÃ©pendances Python
bash
Copier le code
pip install -r requirements.txt
4. Lancer MongoDB avec Docker
bash
Copier le code
docker-compose up -d
â–¶ï¸ ExÃ©cution du pipeline complet
âœ” 1. Collecter les logs Apache
bash
Copier le code
python src/collector.py
âœ” 2. Lancer le modÃ¨le IA

python src/analyzer.py
âœ” 3. Lancer le dashboard
streamlit run src/dashboard.py
Dashboard â†’ http://localhost:8501

ğŸ“Œ Exemples dâ€™anomalies dÃ©tectÃ©es
AccÃ¨s rÃ©pÃ©tÃ©s Ã  /admin ou /login

Burst de requÃªtes en quelques millisecondes

SÃ©ries anormales de 404

Trafic inhabituel Ã  des heures rares

Pages inexistantes (scan dâ€™attaque)

ğŸ“¦ Technologies utilisÃ©es
Python 3

MongoDB (Docker)

Pandas

scikit-learn

Streamlit

Regex / parsing logs Apache
